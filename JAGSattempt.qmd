---
title: "Fire Determinant Project"
format: html
editor: visual
---

```{r}
knitr::opts_chunk$set(echo = TRUE)
Sys.setenv(JAGS_HOME="C:/Program Files/JAGS/JAGS-4.3.1")

# Loading necessary libraries
library(rjags)
library(reshape2)
library(coda)
library(MASS)
library(tidyverse)
library(stargazer)
library(ggplot2)

# Reading in the data
data <- read_csv("actual_data_merge (1).csv")

# Now we will calculate the total fires across the dummy rows
rowsums <- data |>
  select(27:40) |>
  mutate(total = rowSums(across(everything()), na.rm = TRUE))
data$total_fires <- rowsums$total
```

Here we will add a new variable called "fire" into the data set. This variable will be a 1 if at least one fire occurred in the area and will be a 0 if no fires occurred. Due to this variable following a bernoulli distribution we will name our data bernoulli. 

```{r}
# adding the fire variable which takes the value 1 if at least 1 fire occured in the observation.
bernoulli <- data |>
  mutate(fire = ifelse(total_fires > 0,1,0))

# this data is titled bernoulli due to the addition of the 'bernoulli' variable fire.
```

Now we will analyze this data with the "fire" variable added to the data set.

# Data Analysis
## Tables

Count of fire occurrence by region

```{r}
region_fire <- table(bernoulli$Region, bernoulli$total_fires)
dimnames(region_fire) <- list(
  "Region" = c("1", "2", "3"),
  "Number of fires across the years per plot" = c("0","1", "2","3","4","5","6","7","8","9","10"))
region_fire
```

Counts of Region and Category

```{r}
data3 <- bernoulli
table(data3$Region, data3$Category, dnn=c("Region","Name of Category"))
```

## Bar Graphs
```{r}
df <- as.data.frame(region_fire)
```

```{r}
ggplot(df, aes(x = Number.of.fires.across.the.years.per.plot, y = Freq, fill = Region)) +
  geom_bar(stat = "identity") +
  labs(title = "Number of fires per plot, separated by region",
       x = "Number of fires per plot",
       y = "Frequency") +
  facet_wrap(~ Region)
```

As we can see, this data has a lot of observations with 0 fires, we will remove these to better see the distribution of counts of fires per plot by region.

```{r}
# Filtering to remove the count of 0 fires per region
df_no_0_fires <- df[-(1:3),]
```

```{r}
ggplot(df_no_0_fires, aes(x = Number.of.fires.across.the.years.per.plot, y = Freq, fill = Region)) +
  geom_bar(stat = "identity") +
  labs(title = "Number of fires per plot, separated by region (removing counts for 0 fires)",
       x = "Number of fires per plot",
       y = "Frequency") +
  facet_wrap(~ Region)
```
Here we can see Region 1 had a lower count of plots with 1 fire over the years compared to Region 2, however it has more occurrences of plots that had several fires throughout the years.

## Tables and Plots


```{r}
filtered <- bernoulli |>
  group_by(Region) |>
  filter(fire == "1") |>
  select(Region,10:24)
```

Pivoting

```{r}
pivot <- filtered |>
  pivot_longer(
    cols = starts_with("AUG") | starts_with("JUL") | starts_with("SEP"),
    names_to = "month_year",
    values_to = "area_burned") |>
    mutate(year = substr(month_year, nchar(month_year) - 3, nchar(month_year)),
           monthpre = substr(month_year, 1, 3),
           # reordering month for plots
           month = factor(monthpre, levels = c("JUL","AUG","SEP")),
           
    Region = as.factor(Region))
```

```{r}
# Grouping by region, year, and month and filtering each year
month_summary <- pivot |>
  group_by(Region,year,month) |>
  summarize(mean_area_burned = round(mean(area_burned, na.rm = TRUE), 2))
month_summary_2019 <- pivot |>
  group_by(Region,year,month) |>
  summarize(mean_area_burned = round(mean(area_burned, na.rm = TRUE), 2)) |>
  filter(year == 2019)
month_summary_2020 <- pivot |>
  group_by(Region,year,month) |>
  summarize(mean_area_burned = round(mean(area_burned, na.rm = TRUE), 2)) |>
  filter(year == 2020)
month_summary_2021 <- pivot |>
  group_by(Region,year,month) |>
  summarize(mean_area_burned = round(mean(area_burned, na.rm = TRUE), 2)) |>
  filter(year == 2021)
month_summary_2022 <- pivot |>
  group_by(Region,year,month) |>
  summarize(mean_area_burned = round(mean(area_burned, na.rm = TRUE), 2)) |>
  filter(year == 2022)
month_summary_2023 <- pivot |>
  group_by(Region,year,month) |>
  summarize(mean_area_burned = round(mean(area_burned, na.rm = TRUE), 2)) |>
  filter(year == 2023)
```

```{r}
year_summary <- pivot |>
    group_by(Region,year) |>
    summarize(mean_area_burned = round((mean(area_burned, na.rm = TRUE)), 2))
```

For this table, we will look at the average area burned each year in each region, averaged over all 3 months.

```{r}
stargazer(year_summary, type = "text", title = "Averaged Area Burned in Hectares for Each Year Through All Months by Region", digits = 2, summary = FALSE, rownames = FALSE, out = "yearaverages.txt")
```

Next, we will look at the average area burned by month in 2019.

```{r}
stargazer(month_summary_2019, type = "text", title = "Averaged Area Burned in Hectares per Region and Month in 2019", digits = 2, summary = FALSE, rownames = FALSE, out = "2019table.txt")
```

Here we will look at the average area burned in 2020.

```{r}
stargazer(month_summary_2020, type = "text", title = "Averaged Area Burned in Hectares per Region and Month in 2020", digits = 2, summary = FALSE, rownames = FALSE, out = "2020table.txt")
```

Next, we will look at 2021, 2022, and 2023.

```{r}
stargazer(month_summary_2021, type = "text", title = "Averaged Area Burned in Hectares per Region and Month in 2021", digits = 2, summary = FALSE, rownames = FALSE, out = "2021table.txt")
```

```{r}
stargazer(month_summary_2022, type = "text", title = "Averaged Area Burned in Hectares per Region and Month in 2022", digits = 2, summary = FALSE, rownames = FALSE, out = "2022table.txt")
```

```{r}
stargazer(month_summary_2023, type = "text", title = "Averaged Area Burned in Hectares per Region and Month in 2023", digits = 2, summary = FALSE, rownames = FALSE, out = "2023table.txt")
```

Average hectare of burned area, grouped by region, over time.

```{r}
ggplot(year_summary, aes(x = year, y = mean_area_burned, 
                         color = Region, group = Region)) +
  geom_point(size = 3) +
  geom_line() +
  labs(title = "Average Area Burned per Year, Grouped by Region",
              y = "Mean Area Burned in Hectares",
       x = "Year")
```

```{r}
ggplot(month_summary, aes(x = month, y = mean_area_burned, 
                         color = year, group = year)) +
  geom_point(size = 3) +
  geom_line() +
  facet_grid(year ~ Region) +
  labs(title = "Average Area Burned in Hectares per Month, Grouped by Year and Region",
       y = "Mean Area Burned in Hectares",
       x = "Month")
```

## Boxplots

```{r}
pivot_filtered <- pivot |>
  filter(!is.na(area_burned))
ggplot(pivot_filtered, aes(x = Region, y = area_burned, fill = Region)) +
  geom_boxplot() +
  facet_wrap(~ year) +
    labs(title = "Boxplots of Area Burned across Regions and Years",
       y = "Area Burned in Hectares")
```
As you can see, due to the outliers present of the major fires it is hard to see the spread of the area burned, so just for visualization purposes, we will remove them to see the spreads across regions.

Outlier removal function - source: https://sqlpad.io/tutorial/remove-outliers/

```{r}
removeOutliers <- function(data, column_name) {
  Q1 <- quantile(data[[column_name]], 0.25)
  Q3 <- quantile(data[[column_name]], 0.75)
  IQR <- Q3 - Q1
  lower_bound <- Q1 - 1.5 * IQR
  upper_bound <- Q3 + 1.5 * IQR
  return(data[data[[column_name]] >= lower_bound & data[[column_name]] <= upper_bound, ])
}
```

Applying function:

```{r}
boxplot_no_outliers <- removeOutliers(data = pivot_filtered, column_name = "area_burned")
```

```{r}
ggplot(boxplot_no_outliers, aes(x = Region, y = area_burned, fill = Region)) +
  geom_boxplot() +
  facet_wrap(~ year) +
    labs(title = "Boxplots of Area Burned in Hectares across Regions and Years (outliers removed)",
       y = "Area Burned in Hectares",
       caption = "Outliers Removed for Visualization Purposes")
```

```{r}
ggplot(boxplot_no_outliers, aes(x = month, y = area_burned, fill = month)) +
  geom_boxplot() +
  labs(title = "Boxplots of Area Burned in Hectares across Months (outliers removed)",
       y = "Area Burned in Hectares",
       x = "Month",
       caption = "Outliers Removed for Visualization Purposes")

```

```{r}
ggplot(boxplot_no_outliers, aes(x = area_burned)) +
  geom_histogram(
    bins = 20,               
    fill = "lightblue",   
    color = "black") +
  labs(title = "Histogram of Area Burned in Hectares", 
       x = "Area Burned in Hectares",                       
       y = "Frequency",
       caption = "Outliers Removed for Visualization Purposes") +
 facet_wrap(~ month)
```

# Models

## Only main effect for all terms

```{r}
set.seed(0820)
fold <- rep(1:5,2)
fold <- sample(fold)
fold

expit <- function(x){1/(1+exp(-x))}
Y_mean1   <- matrix(NA,10,2)
Y_median1 <- matrix(NA,10,2)
Y_low1    <- matrix(NA,10,2)
Y_high1   <- matrix(NA,10,2)

y=bernoulli$fire
x1 = bernoulli$NEAR_DIST
x2 = bernoulli$Shape_Leng
x3 = bernoulli$Shape_Area
x4 = bernoulli$Region

for(f in 1:5){

    data_jags <- list(y=y[fold!=f], x1 = x1[fold!=f], x2 = x2[fold!=f], x3 = x3[fold!=f], x4 = x4[fold!=f])
    params  <- c("beta0", "beta1","beta2","beta3","beta4")
   
   # Select training data with fold not equal to f

    model_string <- textConnection("model{
      for (i in 1:length(y)) {
        y[i] ~ dbern(p[i])
        logit(p[i]) = beta0 + beta1*x1[i] + beta2*x2[i] + beta3*x3[i] + beta4*x4[i] 
      }
      #Uninformative Priors:
      beta0 ~ dnorm(0, 1/(10)^2 )
      beta1 ~ dnorm(0, 1/(10)^2)
      beta2 ~ dnorm(0, 1/(10)^2)
      beta3 ~ dnorm(0, 1/(10)^2)
      beta4 ~ dnorm(0, 1/(10)^2)
    }")


    model1 <- jags.model(model_string,data = data_jags, n.chains=3,quiet=TRUE)
    update(model1, 100, progress.bar="none")
    coda_samples <- coda.samples(model1, 
                            variable.names=params, 
                            n.iter=1000, progress.bar="none")
    samples <- coda_samples[[1]]

   # Make predictions
   for(i in 1:10){if(fold[i]==f){
      Y_mod1 <- rbernoulli(nrow(samples),expit(samples[,1] + samples[,2]*x1[i] + samples[,3]*x2[i] + samples[,4]*x3[i] + samples[,5]*x4[i]))
      
      Y_mean1   <- mean(Y_mod1)
      Y_median1 <- median(Y_mod1)
      Y_low1    <- quantile(Y_mod1,0.025)
      Y_high1   <- quantile(Y_mod1,0.975)

      ppd1 <- table(Y_mod1-0.1)
   }} 
 }
MSE1   <- mean((Y_mean1-y)^2)
MAD1   <- mean(abs(Y_mean1-y))


# Entering correct coefficient names
custom_names <- c("Intercept", "NEAR_DIST", "Shape_Leng", "Shape_Area", "Region")

# Rename columns in each chain
for (chain in 1:length(coda_samples)) {
  varnames(coda_samples[[chain]]) <- custom_names
}

# Generate and display the summary
summary(coda_samples)

# Compute DIC - n.iter needs to be the same above and below
DIC1    <- dic.samples(model1,n.iter=1000,n.thin = 5, progress.bar="none")
DIC1
```



## Main effects of first three vars

```{r}
Y_mean2   <- matrix(NA,10,2)
Y_median2 <- matrix(NA,10,2)
Y_low2    <- matrix(NA,10,2)
Y_high2   <- matrix(NA,10,2)

for(f in 1:5){

    data_jags2 <- list(y=y[fold!=f], x1 = x1[fold!=f], x2 = x2[fold!=f], x3 = x3[fold!=f])
    params2  <- c("beta0", "beta1","beta2","beta3")
   
   # Select training data with fold not equal to f

    model_string2 <- textConnection("model{
      for (i in 1:length(y)) {
        y[i] ~ dbern(p[i])
        logit(p[i]) = beta0 + beta1*x1[i] + beta2*x2[i] + beta3*x3[i] 
      }
      beta0 ~ dnorm(0 ,1/(10)^2 )
      beta1 ~ dnorm(0, 1/(10)^2)
      beta2 ~ dnorm(0, 1/(10)^2)
      beta3 ~ dnorm(0, 1/(10)^2)
    }")


    model2 <- jags.model(model_string2,data = data_jags2, n.chains=3,quiet=TRUE)
    update(model2, 100, progress.bar="none")
    coda_samples2 <- coda.samples(model2, 
                            variable.names=params2, 
                            n.iter=1000, progress.bar="none")
    samples2 <- coda_samples2[[1]]


   # Make predictions
   for(i in 1:10){if(fold[i]==f){
      Y_mod2 <- rbernoulli(nrow(samples2),expit(samples2[,1] + samples2[,2]*x1[i] + samples2[,3]*x2[i] + samples2[,4]*x3[i]))
      
      Y_mean2   <- mean(Y_mod2)
      Y_median2 <- median(Y_mod2)
      Y_low2    <- quantile(Y_mod2,0.025)
      Y_high2   <- quantile(Y_mod2,0.975)

      ppd2 <- table(Y_mod2-0.1)
   }} 
 }
MSE2   <- mean((Y_mean2-y)^2)
MAD2   <- mean(abs(Y_mean2-y))


# Entering correct coefficient names
custom_names2 <- c("Intercept", "NEAR_DIST", "Shape_Leng", "Shape_Area")

# Rename columns in each chain
for (chain in 1:length(coda_samples2)) {
  varnames(coda_samples2[[chain]]) <- custom_names2
}

# Generate and display the summary
summary(coda_samples2)

# Compute DIC - n.iter needs to be the same above and below
DIC2    <- dic.samples(model2,n.iter=1000,n.thin = 5, progress.bar="none")
DIC2
```




That raised DIC slightly....\
So let's try model with main effects for NEAR_DIST, shape length, and region

## Main effects of x1, x2, and x4

```{r}

Y_mean3   <- matrix(NA,10,2)
Y_median3 <- matrix(NA,10,2)
Y_low3    <- matrix(NA,10,2)
Y_high3   <- matrix(NA,10,2)

for(f in 1:5){

    data_jags3 <- list(y=y[fold!=f], x1 = x1[fold!=f], x2 = x2[fold!=f], x4 = x4[fold!=f])
    params3 <- c("beta0", "beta1","beta2","beta3")
   
   # Select training data with fold not equal to f

    model_string3 <- textConnection("model{
      for (i in 1:length(y)) {
        y[i] ~ dbern(p[i])
        logit(p[i]) = beta0 + beta1*x1[i] + beta2*x2[i] + beta3*x4[i] 
      }
      beta0 ~ dnorm(0 ,1/(10)^2 )
      beta1 ~ dnorm(0, 1/(10)^2)
      beta2 ~ dnorm(0, 1/(10)^2)
      beta3 ~ dnorm(0, 1/(10)^2)
    }")


    model3 <- jags.model(model_string3,data = data_jags3, n.chains=3,quiet=TRUE)
    update(model3, 100, progress.bar="none")
    coda_samples3 <- coda.samples(model3, 
                            variable.names=params3, 
                            n.iter=1000, progress.bar="none")
    samples3 <- coda_samples3[[1]]


   # Make predictions
   for(i in 1:10){if(fold[i]==f){
      Y_mod3 <- rbernoulli(nrow(samples3),expit(samples3[,1] + samples3[,2]*x1[i] + samples3[,3]*x2[i] + samples3[,4]*x4[i]))
      
      Y_mean3   <- mean(Y_mod3)
      Y_median3 <- median(Y_mod3)
      Y_low3    <- quantile(Y_mod3,0.025)
      Y_high3   <- quantile(Y_mod3,0.975)

      ppd3 <- table(Y_mod3-0.1)
   }} 
 }
MSE3   <- mean((Y_mean3-y)^2)
MAD3   <- mean(abs(Y_mean3-y))

# Entering correct coefficient names
custom_names3 <- c("Intercept", "NEAR_DIST", "Shape_Leng", "Region")

# Rename columns in each chain
for (chain in 1:length(coda_samples3)) {
  varnames(coda_samples3[[chain]]) <- custom_names3
}

# Generate and display the summary
summary(coda_samples3)
# Compute DIC - n.iter needs to be the same above and below
DIC3    <- dic.samples(model3,n.iter=1000,n.thin = 5, progress.bar="none")
DIC3
```


## Main effects of x1 and x2

```{r}
Y_mean4   <- matrix(NA,10,2)
Y_median4 <- matrix(NA,10,2)
Y_low4    <- matrix(NA,10,2)
Y_high4   <- matrix(NA,10,2)

for(f in 1:5){

    data_jags4 <- list(y=y[fold!=f], x1 = x1[fold!=f], x2 = x2[fold!=f])
    params4 <- c("beta0", "beta1","beta2")
   
   # Select training data with fold not equal to f

    model_string4 <- textConnection("model{
      for (i in 1:length(y)) {
        y[i] ~ dbern(p[i])
        logit(p[i]) = beta0 + beta1*x1[i] + beta2*x2[i] 
      }
      beta0 ~ dnorm(0 ,1/(10)^2 )
      beta1 ~ dnorm(0, 1/(10)^2)
      beta2 ~ dnorm(0, 1/(10)^2)
    }")


    model4 <- jags.model(model_string4,data = data_jags4, n.chains=3,quiet=TRUE)
    update(model4, 100, progress.bar="none")
    coda_samples4 <- coda.samples(model4, 
                            variable.names=params4, 
                            n.iter=1000, progress.bar="none")
    samples4 <- coda_samples4[[1]]


   # Make predictions
   for(i in 1:10){if(fold[i]==f){
      Y_mod4 <- rbernoulli(nrow(samples4),expit(samples4[,1] + samples4[,2]*x1[i] + samples4[,3]*x2[i]))
      Y_mean4   <- mean(Y_mod4)
      Y_median4 <- median(Y_mod4)
      Y_low4    <- quantile(Y_mod4,0.025)
      Y_high4   <- quantile(Y_mod4,0.975)

      ppd4 <- table(Y_mod4-0.1)
   }} 
 }
MSE4   <- mean((Y_mean4-y)^2)
MAD4   <- mean(abs(Y_mean4-y))
# Entering correct coefficient names
custom_names4 <- c("Intercept", "NEAR_DIST", "Shape_Leng")

# Rename columns in each chain
for (chain in 1:length(coda_samples4)) {
  varnames(coda_samples4[[chain]]) <- custom_names4
}

# Generate and display the summary
summary(coda_samples4)
# Compute DIC - n.iter needs to be the same above and below
DIC4    <- dic.samples(model4,n.iter=1000,n.thin = 5, progress.bar="none")
DIC4
```


## Adding an Interaction Term into Model

```{r}
Y_mean5   <- matrix(NA,10,2)
Y_median5 <- matrix(NA,10,2)
Y_low5    <- matrix(NA,10,2)
Y_high5   <- matrix(NA,10,2)

for(f in 1:5){

    data_jags5 <- list(y=y[fold!=f], x1 = x1[fold!=f], x2 = x2[fold!=f])
    params5 <- c("beta0", "beta1","beta2","beta3")
   
   # Select training data with fold not equal to f

    model_string5 <- textConnection("model{
      for (i in 1:length(y)) {
        y[i] ~ dbern(p[i])
        logit(p[i]) = beta0 + beta1*x1[i] + beta2*x2[i] + beta3*x1[i]*x2[i] 
      }
      beta0 ~ dnorm(0 ,1/(10)^2 )
      beta1 ~ dnorm(0, 1/(10)^2)
      beta2 ~ dnorm(0, 1/(10)^2)
      beta3 ~ dnorm(0, 1/(10)^2)
    }")


    model5 <- jags.model(model_string5,data = data_jags5, n.chains=3,quiet=TRUE)
    update(model5, 100, progress.bar="none")
    coda_samples5 <- coda.samples(model5, 
                            variable.names=params5, 
                            n.iter=1000, progress.bar="none")
    samples5 <- coda_samples5[[1]]


   # Make predictions
   for(i in 1:10){if(fold[i]==f){
      Y_mod5 <- rbernoulli(nrow(samples5),expit(samples5[,1] + samples5[,2]*x1[i] + samples5[,3]*x2[i] + samples5[,4]*x1[i]*x2[i]))
      
      Y_mean5   <- mean(Y_mod5)
      Y_median5 <- median(Y_mod5)
      Y_low5    <- quantile(Y_mod5,0.025)
      Y_high5   <- quantile(Y_mod5,0.975)

      ppd5 <- table(Y_mod5-0.1)
   }} 
 }
MSE5   <- mean((Y_mean5-y)^2)
MAD5   <- mean(abs(Y_mean5-y))

# Entering correct coefficient names
custom_names5 <- c("Intercept", "NEAR_DIST", "Shape_Leng", "NEAR_DIST*Shape_Leng")

# Rename columns in each chain
for (chain in 1:length(coda_samples5)) {
  varnames(coda_samples5[[chain]]) <- custom_names5
}

# Generate and display the summary
summary(coda_samples5)
# Compute DIC - n.iter needs to be the same above and below
DIC5    <- dic.samples(model5,n.iter=1000,n.thin = 5, progress.bar="none")
DIC5

samples_df <- as.data.frame(do.call(rbind, lapply(coda_samples5, as.matrix)))

# Melt the data frame to long format for ggplot2
samples_long <- melt(samples_df)
names(samples_long) <- c("Parameter", "Value")

# Filter to beta3
samples_beta3 <- subset(samples_long, Parameter == "NEAR_DIST*Shape_Leng")

# Beta3 Plot
ggplot(samples_beta3, aes(x=Parameter, y=Value)) +
  geom_boxplot() +
  geom_hline(yintercept=0, linetype="dashed", color="red") +
  labs(title="Boxplot of Interaction Term",
       x="Coefficient of Interaction Term",
       y="Value") +
  theme_minimal()

samples_beta1 <- subset(samples_long, Parameter == "NEAR_DIST")
## Beta1 plot
ggplot(samples_beta1, aes(x=Parameter, y=Value)) +
  geom_boxplot() +
  geom_hline(yintercept=0, linetype="dashed", color="red") +
  labs(title="Boxplot of Distance from Nearest Municipality Slope",
       x="Coefficient of Distance from Nearest Municipality",
       y="Value") +
  theme_minimal()

samples_beta2 <- subset(samples_long, Parameter == "Shape_Leng")
## Beta2 plot
ggplot(samples_beta2, aes(x=Parameter, y=Value)) +
  geom_boxplot() +
  geom_hline(yintercept=0, linetype="dashed", color="red") +
  labs(title="Boxplot of Perimeter of Lot Slope",
       x="Perimeter of Lot Slope",
       y="Value") +
  theme_minimal()
```


## Exponentiating the Coefficients to get in Terms of Odds

```{r}
ND_Odds <- exp(.0772)
SL_Odds <- exp(.0003547)
INT_Odds <- exp(-.000007318)
ND_Odds
SL_Odds
INT_Odds
```


## Interpretation of Beta 1

For each increase in hectare away from a municipality, the odds of a fire occurring increases by 8.03% with the other variables in the model held constant.

## Interpretation of Beta 2

For each increase in feet the perimeter of the lot, the odds of a fire occurring increases by .0355% with the other variables in the model held constant.

## Interpretation of Beta 3

For each increase in unit of the interaction between hectares away from a municipality and perimeter of the lot, the odds of a fire occurring decreases by .0007%.

