---
title: "Fire Determinant Project"
format: html
editor: visual
---

```{r}
knitr::opts_chunk$set(echo = TRUE)

Sys.setenv(JAGS_HOME="C:/Program Files/JAGS/JAGS-4.3.1")

library(rjags)
library(reshape2)
library(coda)
library(MASS)
library(tidyverse)
library(stargazer)
data <- read_csv("actual_data_merge (1).csv")

rowsums <- data |>
  select(27:40) |>
  mutate(total = rowSums(across(everything()), na.rm = TRUE))

data$total_fires <- rowsums$total
# 
# 
# 
# 
# data2 <-  data |>
#   select(-1) |>
#   pivot_longer(cols = colnames(data[,27:40]), names_to = "YearMonth", values_to = "Occurrence" )
```

Here we will add a new variable called "fire" into the data set. This variable will be a 1 if at least one fire occurred in the area and will be a 0 if no fires occurred. Due to this variable following 

```{r}
bernoulli <- data |>
  mutate(fire = ifelse(total_fires > 0,1,0))
# this data is titled bernoulli due to the addition of the 'bernoulli' variable fire.
```

Now we will analyze this data with the "fire" variable added to the data set.

# Data Analysis

```{r}
library(ggplot2)
```

## Tables

Count of fire occurrence by region

```{r}
region_fire <- table(bernoulli$Region, bernoulli$fire)
dimnames(region_fire) <- list(
  "Region" = c("1", "2", "3"),
  "Occurence of at least one fire" = c("No", "Yes"))
region_fire
```

Region and Category counts

```{r}
data3 <- bernoulli
table(data3$Region, data3$Category, dnn=c("Region","Name of Category"))
```

## Bar Graphs

```{r}
df <- as.data.frame(region_fire)
ggplot(df, aes(x = Region, y = Freq, fill = Occurence.of.at.least.one.fire)) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(title = "Occurrence of Fire by Region",
       x = "Region",
       y = "Count",
       fill = "Occurrence of Fire") +
    scale_fill_manual(values = c("No" = "skyblue", "Yes" = "maroon")) 

```

Region 1 appears to have the most fires. We should note that this graph looks skewed because

Percentage of yes with respect to each region:

```{r}
library(tidyverse)
percent <- bernoulli |>
  group_by(Region) |>
  mutate (Region = as.factor(Region)) |>
  summarize(percent = sum(fire)/ n() * 100)
```

```{r}
ggplot(percent, aes(x = Region, y = percent, fill = Region)) +
  geom_bar(stat = "identity") +
  labs(title = "Percentage of Relative Fire Occurences by Region",
       x = "Region",
       y = "Percentage") 
```

## Plots

Average hectacre of burned area, grouped by region, over time.

```{r}
filtered <- bernoulli |>
  group_by(Region) |>
  filter(fire == "1") |>
  select(Region,10:24)
```

Pivoting

```{r}
pivot <- filtered |>
  pivot_longer(
    cols = starts_with("AUG") | starts_with("JUL") | starts_with("SEP"),
    names_to = "month_year",
    values_to = "area_burned") |>
    mutate(year = substr(month_year, nchar(month_year) - 3, nchar(month_year)),
           monthpre = substr(month_year, 1, 3),
           # reordering month for plots
           month = factor(monthpre, levels = c("JUL","AUG","SEP")),
           
    Region = as.factor(Region))
```

```{r}
# Grouping by region, year, and month and filtering each year
month_summary <- pivot |>
  group_by(Region,year,month) |>
  summarize(mean_area_burned = round(mean(area_burned, na.rm = TRUE), 2))
month_summary_2019 <- pivot |>
  group_by(Region,year,month) |>
  summarize(mean_area_burned = round(mean(area_burned, na.rm = TRUE), 2)) |>
  filter(year == 2019)
month_summary_2020 <- pivot |>
  group_by(Region,year,month) |>
  summarize(mean_area_burned = round(mean(area_burned, na.rm = TRUE), 2)) |>
  filter(year == 2020)
month_summary_2021 <- pivot |>
  group_by(Region,year,month) |>
  summarize(mean_area_burned = round(mean(area_burned, na.rm = TRUE), 2)) |>
  filter(year == 2021)
month_summary_2022 <- pivot |>
  group_by(Region,year,month) |>
  summarize(mean_area_burned = round(mean(area_burned, na.rm = TRUE), 2)) |>
  filter(year == 2022)
month_summary_2023 <- pivot |>
  group_by(Region,year,month) |>
  summarize(mean_area_burned = round(mean(area_burned, na.rm = TRUE), 2)) |>
  filter(year == 2023)
```

```{r}
year_summary <- pivot |>
    group_by(Region,year) |>
    summarize(mean_area_burned = round((mean(area_burned, na.rm = TRUE)), 2))
```

For this table, we will look at the average area burned each year in each region, averaged over all 3 months.

```{r}
stargazer(year_summary, type = "text", title = "Averaged Area Burned in Hectares for Each Year Through All Months by Region", digits = 2, summary = FALSE, rownames = FALSE, out = "yearaverages.txt")
```

Next, we will look at the average area burned by month in 2019.

```{r}
stargazer(month_summary_2019, type = "text", title = "Averaged Area Burned in Hectares per Region and Month in 2019", digits = 2, summary = FALSE, rownames = FALSE, out = "2019table.txt")
```

Here we will look at the average area burned in 2020.

```{r}
stargazer(month_summary_2020, type = "text", title = "Averaged Area Burned in Hectares per Region and Month in 2020", digits = 2, summary = FALSE, rownames = FALSE, out = "2020table.txt")
```

Next, we will look at 2021, 2022, and 2023.

```{r}
stargazer(month_summary_2021, type = "text", title = "Averaged Area Burned in Hectares per Region and Month in 2021", digits = 2, summary = FALSE, rownames = FALSE, out = "2021table.txt")
```

```{r}
stargazer(month_summary_2022, type = "text", title = "Averaged Area Burned in Hectares per Region and Month in 2022", digits = 2, summary = FALSE, rownames = FALSE, out = "2022table.txt")
```

```{r}
stargazer(month_summary_2023, type = "text", title = "Averaged Area Burned in Hectares per Region and Month in 2023", digits = 2, summary = FALSE, rownames = FALSE, out = "2023table.txt")
```

```{r}
ggplot(year_summary, aes(x = year, y = mean_area_burned, 
                         color = Region, group = Region)) +
  geom_point(size = 3) +
  geom_line() +
  labs(title = "Average Area Burned per Year, Grouped by Region",
              y = "Mean Area Burned in Hectares",
       x = "Year")
```

```{r}
ggplot(month_summary, aes(x = month, y = mean_area_burned, 
                         color = year, group = year)) +
  geom_point(size = 3) +
  geom_line() +
  facet_grid(year ~ Region) +
  labs(title = "Average Area Burned in Hectares per Month, Grouped by Year and Region",
       y = "Mean Area Burned in Hectares",
       x = "Month")
```

## Boxplots

```{r}
pivot_filtered <- pivot |>
  filter(!is.na(area_burned))
ggplot(pivot_filtered, aes(x = Region, y = area_burned, fill = Region)) +
  geom_boxplot() +
  facet_wrap(~ year) +
    labs(title = "Boxplots of Area Burned across Regions and Years",
       y = "Area Burned in Hectares")
```
As you can see, due to the outliers present of the major fires it is hard to see the spread of the area burned, so just for visualization purposes, we will remove them to see the spreads across regions.

Outlier removal function - source: https://sqlpad.io/tutorial/remove-outliers/

```{r}
removeOutliers <- function(data, column_name) {
  Q1 <- quantile(data[[column_name]], 0.25)
  Q3 <- quantile(data[[column_name]], 0.75)
  IQR <- Q3 - Q1
  lower_bound <- Q1 - 1.5 * IQR
  upper_bound <- Q3 + 1.5 * IQR
  return(data[data[[column_name]] >= lower_bound & data[[column_name]] <= upper_bound, ])
}
```

Applying function:

```{r}
boxplot_no_outliers <- removeOutliers(data = pivot_filtered, column_name = "area_burned")
```

```{r}
ggplot(boxplot_no_outliers, aes(x = Region, y = area_burned, fill = Region)) +
  geom_boxplot() +
  facet_wrap(~ year) +
    labs(title = "Boxplots of Area Burned in Hectares across Regions and Years (outliers removed)",
       y = "Area Burned in Hectares",
       caption = "Outliers Removed for Visualization Purposes")
```

```{r}
ggplot(boxplot_no_outliers, aes(x = month, y = area_burned, fill = month)) +
  geom_boxplot() +
  labs(title = "Boxplots of Area Burned in Hectares across Months (outliers removed)",
       y = "Area Burned in Hectares",
       x = "Month",
       caption = "Outliers Removed for Visualization Purposes")

```

```{r}
ggplot(boxplot_no_outliers, aes(x = area_burned)) +
  geom_histogram(
    bins = 20,               
    fill = "lightblue",   
    color = "black") +
  labs(title = "Histogram of Area Burned in Hectares", 
       x = "Area Burned in Hectares",                       
       y = "Frequency",
       caption = "Outliers Removed for Visualization Purposes") +
 facet_wrap(~ month)
```

# Models

## Only main effect for all terms

```{r}

model_string <- textConnection("model{
    for (i in 1:length(y)) {
      y[i] ~ dbern(p[i])
      logit(p[i]) = beta0 + beta1*x1[i] + beta2*x2[i] + beta3*x3[i] + beta4*x4[i] 
    }
    #Uninformative Priors:
    beta0 ~ dnorm(0, 1/(10)^2 )
    beta1 ~ dnorm(0, 1/(10)^2)
    beta2 ~ dnorm(0, 1/(10)^2)
    beta3 ~ dnorm(0, 1/(10)^2)
    beta4 ~ dnorm(0, 1/(10)^2)

}")

# Dr. Reich does not standardize the data, but other resource does


data_jags = list(y=bernoulli$fire, x1 = bernoulli$NEAR_DIST, x2 = bernoulli$Shape_Leng, x3 = bernoulli$Shape_Area, x4 = bernoulli$Region)

model <- jags.model(model_string,data = data_jags, n.chains=3,quiet=TRUE)
update(model, 100, progress.bar="none")
params  <- c("beta0", "beta1","beta2","beta3","beta4")
samples <- coda.samples(model, 
           variable.names=params, 
           n.iter=1000, progress.bar="none")

# Entering correct coefficient names
custom_names <- c("Intercept", "NEAR_DIST", "Shape_Leng", "Shape_Area", "Region")

# Rename columns in each chain
for (chain in 1:length(samples)) {
  varnames(samples[[chain]]) <- custom_names
}

# Generate and display the summary
summary(samples)

# Compute DIC - n.iter needs to be the same above and below
DIC    <- dic.samples(model,n.iter=1000,n.thin = 5, progress.bar="none")
DIC
```

# CV attempt
```{r}

# Assuming bernoulli is your dataframe containing all data
set.seed(123)  # for reproducibility
n <- nrow(bernoulli)
train_indices <- sample(1:n, round(0.8 * n))  # 80% train, 20% test
test_indices <- setdiff(1:n, train_indices)

# Create training and testing datasets
train_data <- list(
  y = bernoulli$fire[train_indices],
  x1 = bernoulli$NEAR_DIST[train_indices],
  x2 = bernoulli$Shape_Leng[train_indices],
  x3 = bernoulli$Shape_Area[train_indices],
  x4 = bernoulli$Region[train_indices]
)

test_data <- list(
  y = bernoulli$fire[test_indices],
  x1 = bernoulli$NEAR_DIST[test_indices],
  x2 = bernoulli$Shape_Leng[test_indices],
  x3 = bernoulli$Shape_Area[test_indices],
  x4 = bernoulli$Region[test_indices]
)

model_string <- "model {
    for (i in 1:length(y)) {
        y[i] ~ dbern(p[i])
        logit(p[i]) = beta0 + beta1 * x1[i] + beta2 * x2[i] + beta3 * x3[i] + beta4 * x4[i]
    }
    beta0 ~ dnorm(0, 1/(10)^2)
    beta1 ~ dnorm(0, 1/(10)^2)
    beta2 ~ dnorm(0, 1/(10)^2)
    beta3 ~ dnorm(0, 1/(10)^2)
    beta4 ~ dnorm(0, 1/(10)^2)
}
"

model <- jags.model(textConnection(model_string), data = train_data, n.chains = 3, quiet = TRUE)
update(model, 100)  # burn-in

params <- c("beta0", "beta1", "beta2", "beta3", "beta4")
samples <- coda.samples(model, variable.names = params, n.iter = 1000)

# Extract posterior samples
posterior_samples <- as.matrix(samples)

# Calculate logit(p) for test set
logit_p <- posterior_samples[, "beta0"] + 
           posterior_samples[, "beta1"] * test_data$x1 + 
           posterior_samples[, "beta2"] * test_data$x2 + 
           posterior_samples[, "beta3"] * test_data$x3 + 
           posterior_samples[, "beta4"] * test_data$x4

# Calculate predicted probabilities
predicted_probabilities <- 1 / (1 + exp(-logit_p))

# Example: Calculate accuracy
threshold <- 0.5  # Example threshold for binary classification
predictions <- ifelse(predicted_probabilities > threshold, 1, 0)
accuracy <- mean(predictions == test_data$y)
cat("Accuracy:", accuracy, "\n")
```


```{r}
b0 <- c(samples[[1]][,1],samples[[2]][,1])
b1 <- c(samples[[1]][,2],samples[[2]][,2])
b2 <- c(samples[[1]][,3],samples[[2]][,3])
b3 <- c(samples[[1]][,4],samples[[2]][,4])
b4 <- c(samples[[1]][,5],samples[[2]][,5])
```


## Main effects of first three vars

```{r}

model_string2 <- textConnection("model{
    for (i in 1:length(y)) {
      y[i] ~ dbern(p[i])
      logit(p[i]) = beta0 + beta1*x1[i] + beta2*x2[i] + beta3*x3[i]
    }
    #Uninformative Priors:
    beta0 ~ dnorm(0 ,1/(10)^2 )
    beta1 ~ dnorm(0, 1/(10)^2)
    beta2 ~ dnorm(0, 1/(10)^2)
    beta3 ~ dnorm(0, 1/(10)^2)

}")

# Dr. Reich does not standardize the data, but other resource does


data_jags2 = list(y=bernoulli$fire, x1 = bernoulli$NEAR_DIST, x2 = bernoulli$Shape_Leng, x3 = bernoulli$Shape_Area)

model2 <- jags.model(model_string2,data = data_jags2, n.chains=3,quiet=TRUE)
update(model2, 100, progress.bar="none")
params2  <- c("beta0", "beta1","beta2","beta3")
samples2 <- coda.samples(model2, 
           variable.names=params2, 
           n.iter=1000, progress.bar="none")
# Entering correct coefficient names
custom_names2 <- c("Intercept", "NEAR_DIST", "Shape_Leng", "Shape_Area")

# Rename columns in each chain
for (chain in 1:length(samples2)) {
  varnames(samples2[[chain]]) <- custom_names2
}

# Generate and display the summary
summary(samples2)
# Compute DIC - n.iter needs to be the same above and below
DIC2    <- dic.samples(model2,n.iter=1000,n.thin = 5, progress.bar="none")
DIC2
```

# CV attempt 2

```{r}

# Extract posterior samples
posterior_samples2 <- as.matrix(samples2)

# Calculate logit(p) for test set
logit_p2 <- posterior_samples2[, "Intercept"] + 
           posterior_samples2[, "NEAR_DIST"] * test_data$x1 + 
           posterior_samples2[, "Shape_Leng"] * test_data$x2 + 
           posterior_samples2[, "Shape_Area"] * test_data$x3 

# Calculate predicted probabilities
predicted_probabilities2 <- 1 / (1 + exp(-logit_p2))

# Example: Calculate accuracy
threshold <- 0.5  # Example threshold for binary classification
predictions2 <- ifelse(predicted_probabilities2 > threshold, 1, 0)
accuracy2 <- mean(predictions2 == test_data$y)
cat("Accuracy:", accuracy2, "\n")
```


That raised DIC slightly....\
So let's try model with main effects for NEAR_DIST, shape length, and region

## Main effects of x1, x2, and x4

```{r}

model_string3 <- textConnection("model{
    for (i in 1:length(y)) {
      y[i] ~ dbern(p[i])
      logit(p[i]) = beta0 + beta1*x1[i] + beta2*x2[i] + beta3*x4[i]
    }
    #Uninformative Priors:
    beta0 ~ dnorm(0 ,1/(10)^2 )
    beta1 ~ dnorm(0, 1/(10)^2)
    beta2 ~ dnorm(0, 1/(10)^2)
    beta3 ~ dnorm(0, 1/(10)^2)

}")

# Dr. Reich does not standardize the data, but other resource does


data_jags3 = list(y=bernoulli$fire, x1 = bernoulli$NEAR_DIST, x2 = bernoulli$Shape_Leng, x4 = bernoulli$Region)

model3 <- jags.model(model_string3,data = data_jags3, n.chains=3,quiet=TRUE)
update(model3, 100, progress.bar="none")
params3  <- c("beta0", "beta1","beta2","beta3")
samples3 <- coda.samples(model3, 
           variable.names=params3, 
           n.iter=1000, progress.bar="none")
# Entering correct coefficient names
custom_names3 <- c("Intercept", "NEAR_DIST", "Shape_Leng", "Region")

# Rename columns in each chain
for (chain in 1:length(samples3)) {
  varnames(samples3[[chain]]) <- custom_names3
}

# Generate and display the summary
summary(samples3)
# Compute DIC - n.iter needs to be the same above and below
DIC3    <- dic.samples(model3,n.iter=1000,n.thin = 5, progress.bar="none")
DIC3
```

# CV attempt 3

```{r}

# Extract posterior samples
posterior_samples3 <- as.matrix(samples3)

# Calculate logit(p) for test set
logit_p3 <- posterior_samples3[, "Intercept"] + 
           posterior_samples3[, "NEAR_DIST"] * test_data$x1 + 
           posterior_samples3[, "Shape_Leng"] * test_data$x2 + 
           posterior_samples3[, "Region"] * test_data$x4 

# Calculate predicted probabilities
predicted_probabilities3 <- 1 / (1 + exp(-logit_p3))

# Example: Calculate accuracy
threshold <- 0.5  # Example threshold for binary classification
predictions3 <- ifelse(predicted_probabilities3 > threshold, 1, 0)
accuracy3 <- mean(predictions3 == test_data$y)
cat("Accuracy:", accuracy3, "\n")
```

## Main effects of x1 and x2

```{r}
set.seed(50)
model_string4 <- textConnection("model{
    for (i in 1:length(y)) {
      y[i] ~ dbern(p[i])
      logit(p[i]) = beta0 + beta1*x1[i] + beta2*x2[i]
    }
    #Uninformative Priors:
    beta0 ~ dnorm(0 ,1/(10)^2)
    beta1 ~ dnorm(0, 1/(10)^2)
    beta2 ~ dnorm(0, 1/(10)^2)
}")

# Dr. Reich does not standardize the data, but other resource does


data_jags4 = list(y=bernoulli$fire, x1 = bernoulli$NEAR_DIST, x2 = bernoulli$Shape_Leng)

model4 <- jags.model(model_string4,data = data_jags4, n.chains=3,quiet=TRUE)
update(model4, 100, progress.bar="none")
params4  <- c("beta0", "beta1","beta2")
samples4 <- coda.samples(model4, 
           variable.names=params4, 
           n.iter=1000, progress.bar="none")
# Entering correct coefficient names
custom_names4 <- c("Intercept", "NEAR_DIST", "Shape_Leng")

# Rename columns in each chain
for (chain in 1:length(samples4)) {
  varnames(samples4[[chain]]) <- custom_names4
}

# Generate and display the summary
summary(samples4)
# Compute DIC - n.iter needs to be the same above and below
DIC4    <- dic.samples(model4,n.iter=1000,n.thin = 5, progress.bar="none")
DIC4
```

# CV attempt 4

```{r}

# Extract posterior samples
posterior_samples4 <- as.matrix(samples4)

# Calculate logit(p) for test set
logit_p4 <- posterior_samples4[, "Intercept"] + 
           posterior_samples4[, "NEAR_DIST"] * test_data$x1 + 
           posterior_samples4[, "Shape_Leng"] * test_data$x2

# Calculate predicted probabilities
predicted_probabilities4 <- 1 / (1 + exp(-logit_p4))

# Example: Calculate accuracy
threshold <- 0.5  # Example threshold for binary classification
predictions4 <- ifelse(predicted_probabilities4 > threshold, 1, 0)
accuracy4 <- mean(predictions4 == test_data$y)
cat("Accuracy:", accuracy4, "\n")
```

## Adding an Interaction Term into Model

```{r}
set.seed(50)
model_string5 <- textConnection("model{
    for (i in 1:length(y)) {
      y[i] ~ dbern(p[i])
      logit(p[i]) = beta0 + beta1*x1[i] + beta2*x2[i] + beta3*x3[i]
    }
    #Uninformative Priors:
    beta0 ~ dnorm(0 ,1/(10)^2)
    beta1 ~ dnorm(0, 1/(10)^2)
    beta2 ~ dnorm(0, 1/(10)^2)
    beta3 ~ dnorm(0, 1/(10)^2)

}")

# Dr. Reich does not standardize the data, but other resource does


data_jags5 = list(y=bernoulli$fire, x1 = bernoulli$NEAR_DIST, x2 = bernoulli$Shape_Leng, x3 = bernoulli$Shape_Leng*bernoulli$NEAR_DIST)

model5 <- jags.model(model_string5,data = data_jags5, n.chains=3,quiet=TRUE)
update(model5, 100, progress.bar="none")
params5  <- c("beta0", "beta1","beta2", "beta3")
samples5 <- coda.samples(model5, 
           variable.names=params5, 
           n.iter=1000, progress.bar="none")

# Entering correct coefficient names
custom_names5 <- c("Intercept", "NEAR_DIST", "Shape_Leng", "NEAR_DIST*Shape_Leng")

# Rename columns in each chain
for (chain in 1:length(samples5)) {
  varnames(samples5[[chain]]) <- custom_names5
}

# Generate and display the summary
summary(samples5)
# Compute DIC - n.iter needs to be the same above and below
DIC5    <- dic.samples(model5,n.iter=1000,n.thin = 5, progress.bar="none")
DIC5

samples_df <- as.data.frame(do.call(rbind, lapply(samples5, as.matrix)))

# Melt the data frame to long format for ggplot2
samples_long <- melt(samples_df)
names(samples_long) <- c("Parameter", "Value")

# Filter to beta3
samples_beta3 <- subset(samples_long, Parameter == "NEAR_DIST*Shape_Leng")

# Beta3 Plot
ggplot(samples_beta3, aes(x=Parameter, y=Value)) +
  geom_boxplot() +
  geom_hline(yintercept=0, linetype="dashed", color="red") +
  labs(title="Boxplot of Interaction Term",
       x="Coefficient of Interaction Term",
       y="Value") +
  theme_minimal()

samples_beta1 <- subset(samples_long, Parameter == "NEAR_DIST")
## Beta1 plot
ggplot(samples_beta1, aes(x=Parameter, y=Value)) +
  geom_boxplot() +
  geom_hline(yintercept=0, linetype="dashed", color="red") +
  labs(title="Boxplot of Distance from Nearest Municipality Slope",
       x="Coefficient of Distance from Nearest Municipality",
       y="Value") +
  theme_minimal()

samples_beta2 <- subset(samples_long, Parameter == "Shape_Leng")
## Beta2 plot
ggplot(samples_beta2, aes(x=Parameter, y=Value)) +
  geom_boxplot() +
  geom_hline(yintercept=0, linetype="dashed", color="red") +
  labs(title="Boxplot of Perimeter of Lot Slope",
       x="Perimeter of Lot Slope",
       y="Value") +
  theme_minimal()
```

# CV attempt 5

```{r}

# Extract posterior samples
posterior_samples5 <- as.matrix(samples5)

# Calculate logit(p) for test set
logit_p5 <- posterior_samples5[, "Intercept"] + 
           posterior_samples5[, "NEAR_DIST"] * test_data$x1 + 
           posterior_samples5[, "Shape_Leng"] * test_data$x2 + 
           posterior_samples5[, "NEAR_DIST*Shape_Leng"] * test_data$x1 * test_data$x2 

# Calculate predicted probabilities
predicted_probabilities5 <- 1 / (1 + exp(-logit_p5))

# Example: Calculate accuracy
threshold <- 0.5  # Example threshold for binary classification
predictions5 <- ifelse(predicted_probabilities5 > threshold, 1, 0)
accuracy5 <- mean(predictions5 == test_data$y)
cat("Accuracy:", accuracy5, "\n")
```

## Exponentiating the Coefficients to get in Terms of Odds

```{r}
ND_Odds <- exp(.0674)
SL_Odds <- exp(.0003248)
INT_Odds <- exp(-.000007078)
ND_Odds
SL_Odds
INT_Odds
```


## Interpretation of Beta 1

For each increase in hectare away from a municipality, the odds of a fire occurring increases by 6.97% with the other variables in the model held constant.

## Interpretation of Beta 2

For each increase in feet the perimeter of the lot, the odds of a fire occurring increases by .0325% with the other variables in the model held constant.

## Interpretation of Beta 3

For each increase in unit of the interaction between hectares away from a municipality and perimeter of the lot, the odds of a fire occurring decreases by .0007%.

