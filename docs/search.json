[
  {
    "objectID": "JAGSattempt.html",
    "href": "JAGSattempt.html",
    "title": "Fire Determinant Project",
    "section": "",
    "text": "knitr::opts_chunk$set(echo = TRUE)\nSys.setenv(JAGS_HOME=\"C:/Program Files/JAGS/JAGS-4.3.1\")\n\n# Loading necessary libraries\nlibrary(rjags)\n\nWarning: package 'rjags' was built under R version 4.3.3\n\n\nLoading required package: coda\n\n\nWarning: package 'coda' was built under R version 4.3.3\n\n\nLinked to JAGS 4.3.1\n\n\nLoaded modules: basemod,bugs\n\nlibrary(reshape2)\n\nWarning: package 'reshape2' was built under R version 4.3.3\n\nlibrary(coda)\nlibrary(MASS)\n\nWarning: package 'MASS' was built under R version 4.3.2\n\nlibrary(tidyverse)\n\nWarning: package 'tidyverse' was built under R version 4.3.3\n\n\nWarning: package 'tibble' was built under R version 4.3.2\n\n\nWarning: package 'tidyr' was built under R version 4.3.2\n\n\nWarning: package 'readr' was built under R version 4.3.2\n\n\nWarning: package 'purrr' was built under R version 4.3.2\n\n\nWarning: package 'dplyr' was built under R version 4.3.3\n\n\nWarning: package 'stringr' was built under R version 4.3.2\n\n\nWarning: package 'forcats' was built under R version 4.3.2\n\n\nWarning: package 'lubridate' was built under R version 4.3.2\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n✖ dplyr::select() masks MASS::select()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(stargazer)\n\n\nPlease cite as: \n\n Hlavac, Marek (2022). stargazer: Well-Formatted Regression and Summary Statistics Tables.\n R package version 5.2.3. https://CRAN.R-project.org/package=stargazer \n\nlibrary(ggplot2)\n\n# Reading in the data\ndata &lt;- read_csv(\"actual_data_merge (1).csv\")\n\nNew names:\nRows: 1282 Columns: 56\n── Column specification\n──────────────────────────────────────────────────────── Delimiter: \",\" chr\n(3): Name, Category, geometry dbl (52): ...1, ID, NEAR_DIST, Interview,\nShape_Leng, Shape_Area, Region, AU... lgl (1): JUL_2023\nℹ Use `spec()` to retrieve the full column specification for this data. ℹ\nSpecify the column types or set `show_col_types = FALSE` to quiet this message.\n• `` -&gt; `...1`\n\n# Now we will calculate the total fires across the dummy rows\nrowsums &lt;- data |&gt;\n  select(27:40) |&gt;\n  mutate(total = rowSums(across(everything()), na.rm = TRUE))\ndata$total_fires &lt;- rowsums$total\nHere we will add a new variable called “fire” into the data set. This variable will be a 1 if at least one fire occurred in the area and will be a 0 if no fires occurred. Due to this variable following a bernoulli distribution we will name our data bernoulli.\n# adding the fire variable which takes the value 1 if at least 1 fire occured in the observation.\nbernoulli &lt;- data |&gt;\n  mutate(fire = ifelse(total_fires &gt; 0,1,0))\n\n# this data is titled bernoulli due to the addition of the 'bernoulli' variable fire.\nNow we will analyze this data with the “fire” variable added to the data set."
  },
  {
    "objectID": "JAGSattempt.html#tables",
    "href": "JAGSattempt.html#tables",
    "title": "Fire Determinant Project",
    "section": "Tables",
    "text": "Tables\nCount of fire occurrence by region\n\nregion_fire &lt;- table(bernoulli$Region, bernoulli$total_fires)\ndimnames(region_fire) &lt;- list(\n  \"Region\" = c(\"1\", \"2\", \"3\"),\n  \"Number of fires across the years per plot\" = c(\"0\",\"1\", \"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\"))\nregion_fire\n\n      Number of fires across the years per plot\nRegion   0   1   2   3   4   5   6   7   8   9  10\n     1 291  45  18   9   4   1   1   2   3   1   1\n     2 417  49   7   3   1   0   1   0   0   0   0\n     3 367  34  13   8   2   1   0   2   1   0   0\n\n\nCounts of Region and Category\n\ndata3 &lt;- bernoulli\ntable(data3$Region, data3$Category, dnn=c(\"Region\",\"Name of Category\"))\n\n      Name of Category\nRegion Agropolis Agrovila Crossroad Ruropolis\n     1        39      267        70         0\n     2        69      404         5         0\n     3        55      326         8        39"
  },
  {
    "objectID": "JAGSattempt.html#bar-graphs",
    "href": "JAGSattempt.html#bar-graphs",
    "title": "Fire Determinant Project",
    "section": "Bar Graphs",
    "text": "Bar Graphs\n\ndf &lt;- as.data.frame(region_fire)\n\n\nggplot(df, aes(x = Number.of.fires.across.the.years.per.plot, y = Freq, fill = Region)) +\n  geom_bar(stat = \"identity\") +\n  labs(title = \"Number of fires per plot, separated by region\",\n       x = \"Number of fires per plot\",\n       y = \"Frequency\") +\n  facet_wrap(~ Region)\n\n\n\n\nAs we can see, this data has a lot of observations with 0 fires, we will remove these to better see the distribution of counts of fires per plot by region.\n\n# Filtering to remove the count of 0 fires per region\ndf_no_0_fires &lt;- df[-(1:3),]\n\n\nggplot(df_no_0_fires, aes(x = Number.of.fires.across.the.years.per.plot, y = Freq, fill = Region)) +\n  geom_bar(stat = \"identity\") +\n  labs(title = \"Number of fires per plot, separated by region (removing counts for 0 fires)\",\n       x = \"Number of fires per plot\",\n       y = \"Frequency\") +\n  facet_wrap(~ Region)\n\n\n\n\nHere we can see Region 1 had a lower count of plots with 1 fire over the years compared to Region 2, however it has more occurrences of plots that had several fires throughout the years."
  },
  {
    "objectID": "JAGSattempt.html#tables-and-plots",
    "href": "JAGSattempt.html#tables-and-plots",
    "title": "Fire Determinant Project",
    "section": "Tables and Plots",
    "text": "Tables and Plots\n\nfiltered &lt;- bernoulli |&gt;\n  group_by(Region) |&gt;\n  filter(fire == \"1\") |&gt;\n  select(Region,10:24)\n\nPivoting\n\npivot &lt;- filtered |&gt;\n  pivot_longer(\n    cols = starts_with(\"AUG\") | starts_with(\"JUL\") | starts_with(\"SEP\"),\n    names_to = \"month_year\",\n    values_to = \"area_burned\") |&gt;\n    mutate(year = substr(month_year, nchar(month_year) - 3, nchar(month_year)),\n           monthpre = substr(month_year, 1, 3),\n           # reordering month for plots\n           month = factor(monthpre, levels = c(\"JUL\",\"AUG\",\"SEP\")),\n           \n    Region = as.factor(Region))\n\n\n# Grouping by region, year, and month and filtering each year\nmonth_summary &lt;- pivot |&gt;\n  group_by(Region,year,month) |&gt;\n  summarize(mean_area_burned = round(mean(area_burned, na.rm = TRUE), 2))\n\n`summarise()` has grouped output by 'Region', 'year'. You can override using\nthe `.groups` argument.\n\nmonth_summary_2019 &lt;- pivot |&gt;\n  group_by(Region,year,month) |&gt;\n  summarize(mean_area_burned = round(mean(area_burned, na.rm = TRUE), 2)) |&gt;\n  filter(year == 2019)\n\n`summarise()` has grouped output by 'Region', 'year'. You can override using\nthe `.groups` argument.\n\nmonth_summary_2020 &lt;- pivot |&gt;\n  group_by(Region,year,month) |&gt;\n  summarize(mean_area_burned = round(mean(area_burned, na.rm = TRUE), 2)) |&gt;\n  filter(year == 2020)\n\n`summarise()` has grouped output by 'Region', 'year'. You can override using\nthe `.groups` argument.\n\nmonth_summary_2021 &lt;- pivot |&gt;\n  group_by(Region,year,month) |&gt;\n  summarize(mean_area_burned = round(mean(area_burned, na.rm = TRUE), 2)) |&gt;\n  filter(year == 2021)\n\n`summarise()` has grouped output by 'Region', 'year'. You can override using\nthe `.groups` argument.\n\nmonth_summary_2022 &lt;- pivot |&gt;\n  group_by(Region,year,month) |&gt;\n  summarize(mean_area_burned = round(mean(area_burned, na.rm = TRUE), 2)) |&gt;\n  filter(year == 2022)\n\n`summarise()` has grouped output by 'Region', 'year'. You can override using\nthe `.groups` argument.\n\nmonth_summary_2023 &lt;- pivot |&gt;\n  group_by(Region,year,month) |&gt;\n  summarize(mean_area_burned = round(mean(area_burned, na.rm = TRUE), 2)) |&gt;\n  filter(year == 2023)\n\n`summarise()` has grouped output by 'Region', 'year'. You can override using\nthe `.groups` argument.\n\n\n\nyear_summary &lt;- pivot |&gt;\n    group_by(Region,year) |&gt;\n    summarize(mean_area_burned = round((mean(area_burned, na.rm = TRUE)), 2))\n\n`summarise()` has grouped output by 'Region'. You can override using the\n`.groups` argument.\n\n\nFor this table, we will look at the average area burned each year in each region, averaged over all 3 months.\n\nstargazer(year_summary, type = \"text\", title = \"Averaged Area Burned in Hectares for Each Year Through All Months by Region\", digits = 2, summary = FALSE, rownames = FALSE, out = \"yearaverages.txt\")\n\n\nAveraged Area Burned in Hectares for Each Year Through All Months by Region\n============================\nRegion year mean_area_burned\n----------------------------\n1      2019       5.26      \n1      2020       7.12      \n1      2021       2.18      \n1      2022       2.47      \n1      2023       0.59      \n2      2019       5.89      \n2      2020       5.53      \n2      2021       0.67      \n2      2022       2.6       \n2      2023       2.49      \n3      2019       7.92      \n3      2020       9.16      \n3      2021       7.31      \n3      2022       8.66      \n3      2023       5.39      \n----------------------------\n\n\nNext, we will look at the average area burned by month in 2019.\n\nstargazer(month_summary_2019, type = \"text\", title = \"Averaged Area Burned in Hectares per Region and Month in 2019\", digits = 2, summary = FALSE, rownames = FALSE, out = \"2019table.txt\")\n\n\nAveraged Area Burned in Hectares per Region and Month in 2019\n==================================\nRegion year month mean_area_burned\n----------------------------------\n1      2019   1         0.83      \n1      2019   2        12.57      \n1      2019   3         4.12      \n2      2019   1         0.47      \n2      2019   2        16.06      \n2      2019   3         0.97      \n3      2019   1         7.89      \n3      2019   2        10.32      \n3      2019   3         5.92      \n----------------------------------\n\n\nHere we will look at the average area burned in 2020.\n\nstargazer(month_summary_2020, type = \"text\", title = \"Averaged Area Burned in Hectares per Region and Month in 2020\", digits = 2, summary = FALSE, rownames = FALSE, out = \"2020table.txt\")\n\n\nAveraged Area Burned in Hectares per Region and Month in 2020\n==================================\nRegion year month mean_area_burned\n----------------------------------\n1      2020   1         2.01      \n1      2020   2         0.1       \n1      2020   3         9.35      \n2      2020   1         0.24      \n2      2020   2         0.46      \n2      2020   3         6.08      \n3      2020   1         0.79      \n3      2020   2         4.13      \n3      2020   3         10.7      \n----------------------------------\n\n\nNext, we will look at 2021, 2022, and 2023.\n\nstargazer(month_summary_2021, type = \"text\", title = \"Averaged Area Burned in Hectares per Region and Month in 2021\", digits = 2, summary = FALSE, rownames = FALSE, out = \"2021table.txt\")\n\n\nAveraged Area Burned in Hectares per Region and Month in 2021\n==================================\nRegion year month mean_area_burned\n----------------------------------\n1      2021   1         1.94      \n1      2021   2         6.93      \n1      2021   3         1.64      \n2      2021   1         0.05      \n2      2021   2         NaN       \n2      2021   3         2.52      \n3      2021   1         6.89      \n3      2021   2         7.53      \n3      2021   3         NaN       \n----------------------------------\n\n\n\nstargazer(month_summary_2022, type = \"text\", title = \"Averaged Area Burned in Hectares per Region and Month in 2022\", digits = 2, summary = FALSE, rownames = FALSE, out = \"2022table.txt\")\n\n\nAveraged Area Burned in Hectares per Region and Month in 2022\n==================================\nRegion year month mean_area_burned\n----------------------------------\n1      2022   1         4.32      \n1      2022   2         1.68      \n1      2022   3         2.48      \n2      2022   1         0.12      \n2      2022   2         2.44      \n2      2022   3         2.75      \n3      2022   1         3.36      \n3      2022   2         3.34      \n3      2022   3        21.93      \n----------------------------------\n\n\n\nstargazer(month_summary_2023, type = \"text\", title = \"Averaged Area Burned in Hectares per Region and Month in 2023\", digits = 2, summary = FALSE, rownames = FALSE, out = \"2023table.txt\")\n\n\nAveraged Area Burned in Hectares per Region and Month in 2023\n==================================\nRegion year month mean_area_burned\n----------------------------------\n1      2023   1         NaN       \n1      2023   2         0.15      \n1      2023   3         0.89      \n2      2023   1         NaN       \n2      2023   2         0.35      \n2      2023   3         3.2       \n3      2023   1         NaN       \n3      2023   2         0.9       \n3      2023   3         9.88      \n----------------------------------\n\n\nAverage hectare of burned area, grouped by region, over time.\n\nggplot(year_summary, aes(x = year, y = mean_area_burned, \n                         color = Region, group = Region)) +\n  geom_point(size = 3) +\n  geom_line() +\n  labs(title = \"Average Area Burned per Year, Grouped by Region\",\n              y = \"Mean Area Burned in Hectares\",\n       x = \"Year\")\n\n\n\n\n\nggplot(month_summary, aes(x = month, y = mean_area_burned, \n                         color = year, group = year)) +\n  geom_point(size = 3) +\n  geom_line() +\n  facet_grid(year ~ Region) +\n  labs(title = \"Average Area Burned in Hectares per Month, Grouped by Year and Region\",\n       y = \"Mean Area Burned in Hectares\",\n       x = \"Month\")\n\nWarning: Removed 5 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_line()`)."
  },
  {
    "objectID": "JAGSattempt.html#boxplots",
    "href": "JAGSattempt.html#boxplots",
    "title": "Fire Determinant Project",
    "section": "Boxplots",
    "text": "Boxplots\n\npivot_filtered &lt;- pivot |&gt;\n  filter(!is.na(area_burned))\nggplot(pivot_filtered, aes(x = Region, y = area_burned, fill = Region)) +\n  geom_boxplot() +\n  facet_wrap(~ year) +\n    labs(title = \"Boxplots of Area Burned across Regions and Years\",\n       y = \"Area Burned in Hectares\")\n\n\n\n\nAs you can see, due to the outliers present of the major fires it is hard to see the spread of the area burned, so just for visualization purposes, we will remove them to see the spreads across regions.\nOutlier removal function - source: https://sqlpad.io/tutorial/remove-outliers/\n\nremoveOutliers &lt;- function(data, column_name) {\n  Q1 &lt;- quantile(data[[column_name]], 0.25)\n  Q3 &lt;- quantile(data[[column_name]], 0.75)\n  IQR &lt;- Q3 - Q1\n  lower_bound &lt;- Q1 - 1.5 * IQR\n  upper_bound &lt;- Q3 + 1.5 * IQR\n  return(data[data[[column_name]] &gt;= lower_bound & data[[column_name]] &lt;= upper_bound, ])\n}\n\nApplying function:\n\nboxplot_no_outliers &lt;- removeOutliers(data = pivot_filtered, column_name = \"area_burned\")\n\n\nggplot(boxplot_no_outliers, aes(x = Region, y = area_burned, fill = Region)) +\n  geom_boxplot() +\n  facet_wrap(~ year) +\n    labs(title = \"Boxplots of Area Burned in Hectares across Regions and Years (outliers removed)\",\n       y = \"Area Burned in Hectares\",\n       caption = \"Outliers Removed for Visualization Purposes\")\n\n\n\n\n\nggplot(boxplot_no_outliers, aes(x = month, y = area_burned, fill = month)) +\n  geom_boxplot() +\n  labs(title = \"Boxplots of Area Burned in Hectares across Months (outliers removed)\",\n       y = \"Area Burned in Hectares\",\n       x = \"Month\",\n       caption = \"Outliers Removed for Visualization Purposes\")\n\n\n\n\n\nggplot(boxplot_no_outliers, aes(x = area_burned)) +\n  geom_histogram(\n    bins = 20,               \n    fill = \"lightblue\",   \n    color = \"black\") +\n  labs(title = \"Histogram of Area Burned in Hectares\", \n       x = \"Area Burned in Hectares\",                       \n       y = \"Frequency\",\n       caption = \"Outliers Removed for Visualization Purposes\") +\n facet_wrap(~ month)"
  },
  {
    "objectID": "JAGSattempt.html#only-main-effect-for-all-terms",
    "href": "JAGSattempt.html#only-main-effect-for-all-terms",
    "title": "Fire Determinant Project",
    "section": "Only main effect for all terms",
    "text": "Only main effect for all terms\n\nset.seed(0820)\nfold &lt;- rep(1:5,2)\nfold &lt;- sample(fold)\nfold\n\n [1] 2 1 5 2 4 5 3 4 1 3\n\nexpit &lt;- function(x){1/(1+exp(-x))}\nY_mean1   &lt;- matrix(NA,10,2)\nY_median1 &lt;- matrix(NA,10,2)\nY_low1    &lt;- matrix(NA,10,2)\nY_high1   &lt;- matrix(NA,10,2)\n\ny=bernoulli$fire\nx1 = bernoulli$NEAR_DIST\nx2 = bernoulli$Shape_Leng\nx3 = bernoulli$Shape_Area\nx4 = bernoulli$Region\n\nfor(f in 1:5){\n\n    data_jags &lt;- list(y=y[fold!=f], x1 = x1[fold!=f], x2 = x2[fold!=f], x3 = x3[fold!=f], x4 = x4[fold!=f])\n    params  &lt;- c(\"beta0\", \"beta1\",\"beta2\",\"beta3\",\"beta4\")\n   \n   # Select training data with fold not equal to f\n\n    model_string &lt;- textConnection(\"model{\n      for (i in 1:length(y)) {\n        y[i] ~ dbern(p[i])\n        logit(p[i]) = beta0 + beta1*x1[i] + beta2*x2[i] + beta3*x3[i] + beta4*x4[i] \n      }\n      #Uninformative Priors:\n      beta0 ~ dnorm(0, 1/(10)^2 )\n      beta1 ~ dnorm(0, 1/(10)^2)\n      beta2 ~ dnorm(0, 1/(10)^2)\n      beta3 ~ dnorm(0, 1/(10)^2)\n      beta4 ~ dnorm(0, 1/(10)^2)\n    }\")\n\n    model1 &lt;- jags.model(model_string,data = data_jags, n.chains=3,quiet=TRUE)\n    update(model1, 100, progress.bar=\"none\")\n    coda_samples &lt;- coda.samples(model1, \n                            variable.names=params, \n                            n.iter=1000, progress.bar=\"none\")\n    samples &lt;- coda_samples[[1]]\n\n   # Make predictions\n   for(i in 1:10){if(fold[i]==f){\n      Y_mod1 &lt;- rbernoulli(nrow(samples),expit(samples[,1] + samples[,2]*x1[i] + samples[,3]*x2[i] + samples[,4]*x3[i] + samples[,5]*x4[i]))\n      \n      Y_mean1   &lt;- mean(Y_mod1)\n      Y_median1 &lt;- median(Y_mod1)\n      Y_low1    &lt;- quantile(Y_mod1,0.025)\n      Y_high1   &lt;- quantile(Y_mod1,0.975)\n\n      ppd1 &lt;- table(Y_mod1-0.1)\n   }} \n }\n\nWarning: `rbernoulli()` was deprecated in purrr 1.0.0.\n\nMSE1   &lt;- mean((Y_mean1-y)^2)\nMAD1   &lt;- mean(abs(Y_mean1-y))\n\n\n# Entering correct coefficient names\ncustom_names &lt;- c(\"Intercept\", \"NEAR_DIST\", \"Shape_Leng\", \"Shape_Area\", \"Region\")\n\n# Rename columns in each chain\nfor (chain in 1:length(coda_samples)) {\n  varnames(coda_samples[[chain]]) &lt;- custom_names\n}\n\n# Generate and display the summary\nsummary(coda_samples)\n\n\nIterations = 1101:2100\nThinning interval = 1 \nNumber of chains = 3 \nSample size per chain = 1000 \n\n1. Empirical mean and standard deviation for each variable,\n   plus standard error of the mean:\n\n                 Mean        SD  Naive SE Time-series SE\nIntercept  -2.531e+00 5.897e-01 1.077e-02      9.599e-02\nNEAR_DIST   3.408e-02 1.395e-02 2.547e-04      8.809e-04\nShape_Leng  1.139e-04 9.257e-05 1.690e-06      1.518e-05\nShape_Area  1.854e-07 1.181e-07 2.156e-09      1.562e-08\nRegion     -1.798e-01 1.387e-01 2.533e-03      1.199e-02\n\n2. Quantiles for each variable:\n\n                 2.5%        25%        50%        75%      97.5%\nIntercept  -3.725e+00 -2.943e+00 -2.536e+00 -2.088e+00 -1.474e+00\nNEAR_DIST   5.714e-03  2.469e-02  3.422e-02  4.379e-02  6.196e-02\nShape_Leng -5.480e-05  4.691e-05  1.120e-04  1.814e-04  2.885e-04\nShape_Area -3.454e-08  1.007e-07  1.859e-07  2.656e-07  4.152e-07\nRegion     -4.627e-01 -2.740e-01 -1.742e-01 -8.217e-02  8.058e-02\n\n# Compute DIC - n.iter needs to be the same above and below\nDIC1    &lt;- dic.samples(model1,n.iter=1000,n.thin = 5, progress.bar=\"none\")\nDIC1\n\nMean deviance:  827.3 \npenalty 5.333 \nPenalized deviance: 832.6"
  },
  {
    "objectID": "JAGSattempt.html#main-effects-of-first-three-vars",
    "href": "JAGSattempt.html#main-effects-of-first-three-vars",
    "title": "Fire Determinant Project",
    "section": "Main effects of first three vars",
    "text": "Main effects of first three vars\n\nY_mean2   &lt;- matrix(NA,10,2)\nY_median2 &lt;- matrix(NA,10,2)\nY_low2    &lt;- matrix(NA,10,2)\nY_high2   &lt;- matrix(NA,10,2)\n\nfor(f in 1:5){\n\n    data_jags2 &lt;- list(y=y[fold!=f], x1 = x1[fold!=f], x2 = x2[fold!=f], x3 = x3[fold!=f])\n    params2  &lt;- c(\"beta0\", \"beta1\",\"beta2\",\"beta3\")\n   \n   # Select training data with fold not equal to f\n\n    model_string2 &lt;- textConnection(\"model{\n      for (i in 1:length(y)) {\n        y[i] ~ dbern(p[i])\n        logit(p[i]) = beta0 + beta1*x1[i] + beta2*x2[i] + beta3*x3[i] \n      }\n      beta0 ~ dnorm(0 ,1/(10)^2 )\n      beta1 ~ dnorm(0, 1/(10)^2)\n      beta2 ~ dnorm(0, 1/(10)^2)\n      beta3 ~ dnorm(0, 1/(10)^2)\n    }\")\n\n    model2 &lt;- jags.model(model_string2,data = data_jags2, n.chains=3,quiet=TRUE)\n    update(model2, 100, progress.bar=\"none\")\n    coda_samples2 &lt;- coda.samples(model2, \n                            variable.names=params2, \n                            n.iter=1000, progress.bar=\"none\")\n    samples2 &lt;- coda_samples2[[1]]\n\n\n   # Make predictions\n   for(i in 1:10){if(fold[i]==f){\n      Y_mod2 &lt;- rbernoulli(nrow(samples2),expit(samples2[,1] + samples2[,2]*x1[i] + samples2[,3]*x2[i] + samples2[,4]*x3[i]))\n      \n      Y_mean2   &lt;- mean(Y_mod2)\n      Y_median2 &lt;- median(Y_mod2)\n      Y_low2    &lt;- quantile(Y_mod2,0.025)\n      Y_high2   &lt;- quantile(Y_mod2,0.975)\n\n      ppd2 &lt;- table(Y_mod2-0.1)\n   }} \n }\nMSE2   &lt;- mean((Y_mean2-y)^2)\nMAD2   &lt;- mean(abs(Y_mean2-y))\n\n\n# Entering correct coefficient names\ncustom_names2 &lt;- c(\"Intercept\", \"NEAR_DIST\", \"Shape_Leng\", \"Shape_Area\")\n\n# Rename columns in each chain\nfor (chain in 1:length(coda_samples2)) {\n  varnames(coda_samples2[[chain]]) &lt;- custom_names2\n}\n\n# Generate and display the summary\nsummary(coda_samples2)\n\n\nIterations = 1101:2100\nThinning interval = 1 \nNumber of chains = 3 \nSample size per chain = 1000 \n\n1. Empirical mean and standard deviation for each variable,\n   plus standard error of the mean:\n\n                 Mean        SD  Naive SE Time-series SE\nIntercept  -3.021e+00 3.315e-01 6.053e-03      3.443e-02\nNEAR_DIST   3.849e-02 1.280e-02 2.337e-04      7.611e-04\nShape_Leng  1.400e-04 7.667e-05 1.400e-06      9.499e-06\nShape_Area  1.548e-07 1.027e-07 1.874e-09      9.320e-09\n\n2. Quantiles for each variable:\n\n                 2.5%        25%        50%        75%      97.5%\nIntercept  -3.751e+00 -3.232e+00 -3.006e+00 -2.790e+00 -2.437e+00\nNEAR_DIST   1.367e-02  3.018e-02  3.865e-02  4.717e-02  6.320e-02\nShape_Leng -1.546e-06  8.401e-05  1.379e-04  1.877e-04  3.043e-04\nShape_Area -3.746e-08  8.251e-08  1.540e-07  2.256e-07  3.558e-07\n\n# Compute DIC - n.iter needs to be the same above and below\nDIC2    &lt;- dic.samples(model2,n.iter=1000,n.thin = 5, progress.bar=\"none\")\nDIC2\n\nMean deviance:  828.4 \npenalty 3.904 \nPenalized deviance: 832.3 \n\n\nThat raised DIC slightly….\nSo let’s try model with main effects for NEAR_DIST, shape length, and region"
  },
  {
    "objectID": "JAGSattempt.html#main-effects-of-x1-x2-and-x4",
    "href": "JAGSattempt.html#main-effects-of-x1-x2-and-x4",
    "title": "Fire Determinant Project",
    "section": "Main effects of x1, x2, and x4",
    "text": "Main effects of x1, x2, and x4\n\nY_mean3   &lt;- matrix(NA,10,2)\nY_median3 &lt;- matrix(NA,10,2)\nY_low3    &lt;- matrix(NA,10,2)\nY_high3   &lt;- matrix(NA,10,2)\n\nfor(f in 1:5){\n\n    data_jags3 &lt;- list(y=y[fold!=f], x1 = x1[fold!=f], x2 = x2[fold!=f], x4 = x4[fold!=f])\n    params3 &lt;- c(\"beta0\", \"beta1\",\"beta2\",\"beta3\")\n   \n   # Select training data with fold not equal to f\n\n    model_string3 &lt;- textConnection(\"model{\n      for (i in 1:length(y)) {\n        y[i] ~ dbern(p[i])\n        logit(p[i]) = beta0 + beta1*x1[i] + beta2*x2[i] + beta3*x4[i] \n      }\n      beta0 ~ dnorm(0 ,1/(10)^2 )\n      beta1 ~ dnorm(0, 1/(10)^2)\n      beta2 ~ dnorm(0, 1/(10)^2)\n      beta3 ~ dnorm(0, 1/(10)^2)\n    }\")\n\n    model3 &lt;- jags.model(model_string3,data = data_jags3, n.chains=3,quiet=TRUE)\n    update(model3, 100, progress.bar=\"none\")\n    coda_samples3 &lt;- coda.samples(model3, \n                            variable.names=params3, \n                            n.iter=1000, progress.bar=\"none\")\n    samples3 &lt;- coda_samples3[[1]]\n\n\n   # Make predictions\n   for(i in 1:10){if(fold[i]==f){\n      Y_mod3 &lt;- rbernoulli(nrow(samples3),expit(samples3[,1] + samples3[,2]*x1[i] + samples3[,3]*x2[i] + samples3[,4]*x4[i]))\n      \n      Y_mean3   &lt;- mean(Y_mod3)\n      Y_median3 &lt;- median(Y_mod3)\n      Y_low3    &lt;- quantile(Y_mod3,0.025)\n      Y_high3   &lt;- quantile(Y_mod3,0.975)\n\n      ppd3 &lt;- table(Y_mod3-0.1)\n   }} \n }\nMSE3   &lt;- mean((Y_mean3-y)^2)\nMAD3   &lt;- mean(abs(Y_mean3-y))\n\n# Entering correct coefficient names\ncustom_names3 &lt;- c(\"Intercept\", \"NEAR_DIST\", \"Shape_Leng\", \"Region\")\n\n# Rename columns in each chain\nfor (chain in 1:length(coda_samples3)) {\n  varnames(coda_samples3[[chain]]) &lt;- custom_names3\n}\n\n# Generate and display the summary\nsummary(coda_samples3)\n\n\nIterations = 1101:2100\nThinning interval = 1 \nNumber of chains = 3 \nSample size per chain = 1000 \n\n1. Empirical mean and standard deviation for each variable,\n   plus standard error of the mean:\n\n                 Mean        SD  Naive SE Time-series SE\nIntercept  -3.0000943 3.886e-01 7.095e-03      4.710e-02\nNEAR_DIST   0.0318221 1.289e-02 2.354e-04      7.612e-04\nShape_Leng  0.0002417 3.943e-05 7.199e-07      2.908e-06\nRegion     -0.1371596 1.168e-01 2.132e-03      9.674e-03\n\n2. Quantiles for each variable:\n\n                2.5%        25%        50%        75%      97.5%\nIntercept  -3.774781 -3.2824222 -2.9835101 -2.7102117 -2.3097626\nNEAR_DIST   0.005562  0.0232489  0.0316589  0.0404771  0.0580504\nShape_Leng  0.000165  0.0002146  0.0002406  0.0002684  0.0003223\nRegion     -0.362592 -0.2187883 -0.1416696 -0.0568317  0.0934541\n\n# Compute DIC - n.iter needs to be the same above and below\nDIC3    &lt;- dic.samples(model3,n.iter=1000,n.thin = 5, progress.bar=\"none\")\nDIC3\n\nMean deviance:  828.7 \npenalty 3.923 \nPenalized deviance: 832.6"
  },
  {
    "objectID": "JAGSattempt.html#main-effects-of-x1-and-x2",
    "href": "JAGSattempt.html#main-effects-of-x1-and-x2",
    "title": "Fire Determinant Project",
    "section": "Main effects of x1 and x2",
    "text": "Main effects of x1 and x2\n\nY_mean4   &lt;- matrix(NA,10,2)\nY_median4 &lt;- matrix(NA,10,2)\nY_low4    &lt;- matrix(NA,10,2)\nY_high4   &lt;- matrix(NA,10,2)\n\nfor(f in 1:5){\n\n    data_jags4 &lt;- list(y=y[fold!=f], x1 = x1[fold!=f], x2 = x2[fold!=f])\n    params4 &lt;- c(\"beta0\", \"beta1\",\"beta2\")\n   \n   # Select training data with fold not equal to f\n\n    model_string4 &lt;- textConnection(\"model{\n      for (i in 1:length(y)) {\n        y[i] ~ dbern(p[i])\n        logit(p[i]) = beta0 + beta1*x1[i] + beta2*x2[i] \n      }\n      beta0 ~ dnorm(0 ,1/(10)^2 )\n      beta1 ~ dnorm(0, 1/(10)^2)\n      beta2 ~ dnorm(0, 1/(10)^2)\n    }\")\n\n    model4 &lt;- jags.model(model_string4,data = data_jags4, n.chains=3,quiet=TRUE)\n    update(model4, 100, progress.bar=\"none\")\n    coda_samples4 &lt;- coda.samples(model4, \n                            variable.names=params4, \n                            n.iter=1000, progress.bar=\"none\")\n    samples4 &lt;- coda_samples4[[1]]\n\n\n   # Make predictions\n   for(i in 1:10){if(fold[i]==f){\n      Y_mod4 &lt;- rbernoulli(nrow(samples4),expit(samples4[,1] + samples4[,2]*x1[i] + samples4[,3]*x2[i]))\n      Y_mean4   &lt;- mean(Y_mod4)\n      Y_median4 &lt;- median(Y_mod4)\n      Y_low4    &lt;- quantile(Y_mod4,0.025)\n      Y_high4   &lt;- quantile(Y_mod4,0.975)\n\n      ppd4 &lt;- table(Y_mod4-0.1)\n   }} \n }\nMSE4   &lt;- mean((Y_mean4-y)^2)\nMAD4   &lt;- mean(abs(Y_mean4-y))\n# Entering correct coefficient names\ncustom_names4 &lt;- c(\"Intercept\", \"NEAR_DIST\", \"Shape_Leng\")\n\n# Rename columns in each chain\nfor (chain in 1:length(coda_samples4)) {\n  varnames(coda_samples4[[chain]]) &lt;- custom_names4\n}\n\n# Generate and display the summary\nsummary(coda_samples4)\n\n\nIterations = 1101:2100\nThinning interval = 1 \nNumber of chains = 3 \nSample size per chain = 1000 \n\n1. Empirical mean and standard deviation for each variable,\n   plus standard error of the mean:\n\n                 Mean        SD  Naive SE Time-series SE\nIntercept  -3.3772945 0.2495606 4.556e-03      1.805e-02\nNEAR_DIST   0.0361069 0.0131220 2.396e-04      8.093e-04\nShape_Leng  0.0002527 0.0000373 6.810e-07      2.482e-06\n\n2. Quantiles for each variable:\n\n                 2.5%        25%        50%        75%      97.5%\nIntercept  -3.8283782 -3.5515561 -3.3843558 -3.2036253 -2.8693054\nNEAR_DIST   0.0105523  0.0270273  0.0361340  0.0457339  0.0608228\nShape_Leng  0.0001792  0.0002282  0.0002525  0.0002779  0.0003281\n\n# Compute DIC - n.iter needs to be the same above and below\nDIC4    &lt;- dic.samples(model4,n.iter=1000,n.thin = 5, progress.bar=\"none\")\nDIC4\n\nMean deviance:  829.2 \npenalty 3.056 \nPenalized deviance: 832.3"
  },
  {
    "objectID": "JAGSattempt.html#adding-an-interaction-term-into-model",
    "href": "JAGSattempt.html#adding-an-interaction-term-into-model",
    "title": "Fire Determinant Project",
    "section": "Adding an Interaction Term into Model",
    "text": "Adding an Interaction Term into Model\n\nY_mean5   &lt;- matrix(NA,10,2)\nY_median5 &lt;- matrix(NA,10,2)\nY_low5    &lt;- matrix(NA,10,2)\nY_high5   &lt;- matrix(NA,10,2)\n\nfor(f in 1:5){\n\n    data_jags5 &lt;- list(y=y[fold!=f], x1 = x1[fold!=f], x2 = x2[fold!=f])\n    params5 &lt;- c(\"beta0\", \"beta1\",\"beta2\",\"beta3\")\n   \n   # Select training data with fold not equal to f\n\n    model_string5 &lt;- textConnection(\"model{\n      for (i in 1:length(y)) {\n        y[i] ~ dbern(p[i])\n        logit(p[i]) = beta0 + beta1*x1[i] + beta2*x2[i] + beta3*x1[i]*x2[i] \n      }\n      beta0 ~ dnorm(0 ,1/(10)^2 )\n      beta1 ~ dnorm(0, 1/(10)^2)\n      beta2 ~ dnorm(0, 1/(10)^2)\n      beta3 ~ dnorm(0, 1/(10)^2)\n    }\")\n\n    model5 &lt;- jags.model(model_string5,data = data_jags5, n.chains=3,quiet=TRUE)\n    update(model5, 100, progress.bar=\"none\")\n    coda_samples5 &lt;- coda.samples(model5, \n                            variable.names=params5, \n                            n.iter=1000, progress.bar=\"none\")\n    samples5 &lt;- coda_samples5[[1]]\n\n\n   # Make predictions\n   for(i in 1:10){if(fold[i]==f){\n      Y_mod5 &lt;- rbernoulli(nrow(samples5),expit(samples5[,1] + samples5[,2]*x1[i] + samples5[,3]*x2[i] + samples5[,4]*x1[i]*x2[i]))\n      \n      Y_mean5   &lt;- mean(Y_mod5)\n      Y_median5 &lt;- median(Y_mod5)\n      Y_low5    &lt;- quantile(Y_mod5,0.025)\n      Y_high5   &lt;- quantile(Y_mod5,0.975)\n\n      ppd5 &lt;- table(Y_mod5-0.1)\n   }} \n }\nMSE5   &lt;- mean((Y_mean5-y)^2)\nMAD5   &lt;- mean(abs(Y_mean5-y))\n\n# Entering correct coefficient names\ncustom_names5 &lt;- c(\"Intercept\", \"NEAR_DIST\", \"Shape_Leng\", \"NEAR_DIST*Shape_Leng\")\n\n# Rename columns in each chain\nfor (chain in 1:length(coda_samples5)) {\n  varnames(coda_samples5[[chain]]) &lt;- custom_names5\n}\n\n# Generate and display the summary\nsummary(coda_samples5)\n\n\nIterations = 1101:2100\nThinning interval = 1 \nNumber of chains = 3 \nSample size per chain = 1000 \n\n1. Empirical mean and standard deviation for each variable,\n   plus standard error of the mean:\n\n                           Mean        SD  Naive SE Time-series SE\nIntercept            -3.828e+00 4.124e-01 7.529e-03      7.106e-02\nNEAR_DIST             7.281e-02 2.405e-02 4.390e-04      3.496e-03\nShape_Leng            3.350e-04 7.290e-05 1.331e-06      1.068e-05\nNEAR_DIST*Shape_Leng -6.317e-06 3.682e-06 6.722e-08      5.578e-07\n\n2. Quantiles for each variable:\n\n                           2.5%        25%        50%        75%      97.5%\nIntercept            -4.584e+00 -4.124e+00 -3.837e+00 -3.520e+00 -3.042e+00\nNEAR_DIST             2.583e-02  5.621e-02  7.305e-02  8.923e-02  1.171e-01\nShape_Leng            1.970e-04  2.808e-04  3.382e-04  3.851e-04  4.695e-04\nNEAR_DIST*Shape_Leng -1.329e-05 -8.910e-06 -6.335e-06 -3.799e-06  6.438e-07\n\n# Compute DIC - n.iter needs to be the same above and below\nDIC5    &lt;- dic.samples(model5,n.iter=1000,n.thin = 5, progress.bar=\"none\")\nDIC5\n\nMean deviance:  825.9 \npenalty 4.369 \nPenalized deviance: 830.2 \n\nsamples_df &lt;- as.data.frame(do.call(rbind, lapply(coda_samples5, as.matrix)))\n\n# Melt the data frame to long format for ggplot2\nsamples_long &lt;- melt(samples_df)\n\nNo id variables; using all as measure variables\n\nnames(samples_long) &lt;- c(\"Parameter\", \"Value\")\n\n# Filter to beta3\nsamples_beta3 &lt;- subset(samples_long, Parameter == \"NEAR_DIST*Shape_Leng\")\n\n# Beta3 Plot\nggplot(samples_beta3, aes(x=Parameter, y=Value)) +\n  geom_boxplot() +\n  geom_hline(yintercept=0, linetype=\"dashed\", color=\"red\") +\n  labs(title=\"Boxplot of Interaction Term\",\n       x=\"Coefficient of Interaction Term\",\n       y=\"Value\") +\n  theme_minimal()\n\n\n\nsamples_beta1 &lt;- subset(samples_long, Parameter == \"NEAR_DIST\")\n## Beta1 plot\nggplot(samples_beta1, aes(x=Parameter, y=Value)) +\n  geom_boxplot() +\n  geom_hline(yintercept=0, linetype=\"dashed\", color=\"red\") +\n  labs(title=\"Boxplot of Distance from Nearest Municipality Slope\",\n       x=\"Coefficient of Distance from Nearest Municipality\",\n       y=\"Value\") +\n  theme_minimal()\n\n\n\nsamples_beta2 &lt;- subset(samples_long, Parameter == \"Shape_Leng\")\n## Beta2 plot\nggplot(samples_beta2, aes(x=Parameter, y=Value)) +\n  geom_boxplot() +\n  geom_hline(yintercept=0, linetype=\"dashed\", color=\"red\") +\n  labs(title=\"Boxplot of Perimeter of Lot Slope\",\n       x=\"Perimeter of Lot Slope\",\n       y=\"Value\") +\n  theme_minimal()"
  },
  {
    "objectID": "JAGSattempt.html#exponentiating-the-coefficients-to-get-in-terms-of-odds",
    "href": "JAGSattempt.html#exponentiating-the-coefficients-to-get-in-terms-of-odds",
    "title": "Fire Determinant Project",
    "section": "Exponentiating the Coefficients to get in Terms of Odds",
    "text": "Exponentiating the Coefficients to get in Terms of Odds\n\nND_Odds &lt;- exp(.0772)\nSL_Odds &lt;- exp(.0003547)\nINT_Odds &lt;- exp(-.000007318)\nND_Odds\n\n[1] 1.080258\n\nSL_Odds\n\n[1] 1.000355\n\nINT_Odds\n\n[1] 0.9999927"
  },
  {
    "objectID": "JAGSattempt.html#interpretation-of-beta-1",
    "href": "JAGSattempt.html#interpretation-of-beta-1",
    "title": "Fire Determinant Project",
    "section": "Interpretation of Beta 1",
    "text": "Interpretation of Beta 1\nFor each increase in hectare away from a municipality, the odds of a fire occurring increases by 8.03% with the other variables in the model held constant."
  },
  {
    "objectID": "JAGSattempt.html#interpretation-of-beta-2",
    "href": "JAGSattempt.html#interpretation-of-beta-2",
    "title": "Fire Determinant Project",
    "section": "Interpretation of Beta 2",
    "text": "Interpretation of Beta 2\nFor each increase in feet the perimeter of the lot, the odds of a fire occurring increases by .0355% with the other variables in the model held constant."
  },
  {
    "objectID": "JAGSattempt.html#interpretation-of-beta-3",
    "href": "JAGSattempt.html#interpretation-of-beta-3",
    "title": "Fire Determinant Project",
    "section": "Interpretation of Beta 3",
    "text": "Interpretation of Beta 3\nFor each increase in unit of the interaction between hectares away from a municipality and perimeter of the lot, the odds of a fire occurring decreases by .0007%."
  },
  {
    "objectID": "ProjectWork.html",
    "href": "ProjectWork.html",
    "title": "ProjectWork",
    "section": "",
    "text": "Data Handling\n\nlibrary(tidyverse)\n\nWarning: package 'tidyverse' was built under R version 4.3.3\n\n\nWarning: package 'tibble' was built under R version 4.3.2\n\n\nWarning: package 'tidyr' was built under R version 4.3.2\n\n\nWarning: package 'readr' was built under R version 4.3.2\n\n\nWarning: package 'purrr' was built under R version 4.3.2\n\n\nWarning: package 'dplyr' was built under R version 4.3.3\n\n\nWarning: package 'stringr' was built under R version 4.3.2\n\n\nWarning: package 'forcats' was built under R version 4.3.2\n\n\nWarning: package 'lubridate' was built under R version 4.3.2\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\ndata &lt;- read_csv(\"actual_data_merge (1).csv\") |&gt;\nselect(-c(1))\n\nNew names:\nRows: 1282 Columns: 56\n── Column specification\n──────────────────────────────────────────────────────── Delimiter: \",\" chr\n(3): Name, Category, geometry dbl (52): ...1, ID, NEAR_DIST, Interview,\nShape_Leng, Shape_Area, Region, AU... lgl (1): JUL_2023\nℹ Use `spec()` to retrieve the full column specification for this data. ℹ\nSpecify the column types or set `show_col_types = FALSE` to quiet this message.\n• `` -&gt; `...1`\n\n  rowsums &lt;- data |&gt;\n  select(AUG_2019_dummy:SEP_2023_dummy) |&gt;\n  mutate(total = rowSums(across(everything()), na.rm = TRUE))\n\ndata$total_fires &lt;- rowsums$total\n\n\n\ndata2 &lt;-  data |&gt;\n  pivot_longer(cols = colnames(data[,9:23]), names_to = \"YearMonth\", values_to = \"Occurence\" ) |&gt;\n  select(ID, YearMonth, NEAR_DIST, Name, Category, Interview, Shape_Leng, Shape_Area, Region, YearMonth, total_fires, everything())\ndata2\n\n# A tibble: 19,230 × 43\n           ID YearMonth NEAR_DIST Name  Category Interview Shape_Leng Shape_Area\n        &lt;dbl&gt; &lt;chr&gt;         &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;        &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;\n 1    3.00e10 AUG_2019       11.6 Novo… Agrovila         1      4473.    491009.\n 2    3.00e10 AUG_2020       11.6 Novo… Agrovila         1      4473.    491009.\n 3    3.00e10 AUG_2021       11.6 Novo… Agrovila         1      4473.    491009.\n 4    3.00e10 AUG_2022       11.6 Novo… Agrovila         1      4473.    491009.\n 5    3.00e10 AUG_2023       11.6 Novo… Agrovila         1      4473.    491009.\n 6    3.00e10 JUL_2019       11.6 Novo… Agrovila         1      4473.    491009.\n 7    3.00e10 JUL_2020       11.6 Novo… Agrovila         1      4473.    491009.\n 8    3.00e10 JUL_2021       11.6 Novo… Agrovila         1      4473.    491009.\n 9    3.00e10 JUL_2022       11.6 Novo… Agrovila         1      4473.    491009.\n10    3.00e10 JUL_2023       11.6 Novo… Agrovila         1      4473.    491009.\n# ℹ 19,220 more rows\n# ℹ 35 more variables: Region &lt;dbl&gt;, total_fires &lt;dbl&gt;, `Grand Tota` &lt;dbl&gt;,\n#   geometry &lt;chr&gt;, AUG_2019_dummy &lt;dbl&gt;, AUG_2020_dummy &lt;dbl&gt;,\n#   AUG_2021_dummy &lt;dbl&gt;, AUG_2022_dummy &lt;dbl&gt;, AUG_2023_dummy &lt;dbl&gt;,\n#   JUL_2019_dummy &lt;dbl&gt;, JUL_2020_dummy &lt;dbl&gt;, JUL_2021_dummy &lt;dbl&gt;,\n#   JUL_2022_dummy &lt;dbl&gt;, SEP_2019_dummy &lt;dbl&gt;, SEP_2020_dummy &lt;dbl&gt;,\n#   SEP_2021_dummy &lt;dbl&gt;, SEP_2022_dummy &lt;dbl&gt;, SEP_2023_dummy &lt;dbl&gt;, …"
  }
]